{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "plt.style.use(\"ggplot\")\n",
    "from installing_a_printer.utils import load_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_behavior.envs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task_name = 'SimpleInstallingAPrinter'\n",
    "# env_name = f'MiniGrid-{task_name}-16x16-N2-v1'\n",
    "env_name = f'MiniGrid-{task_name}-8x8-N2-v0'\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "action_space_size = env.action_space.n\n",
    "state_space_size  = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "\n",
    "split = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_split_idx(num_samples, split=0.8):\n",
    "    np.random.seed(0)\n",
    "    train_idx = np.random.choice(num_samples, int(split * num_samples))\n",
    "    test_idx = [i for i in range(num_samples) if i not in train_idx]\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "\n",
    "class DemoDataset(Dataset):\n",
    "    def __init__(self, demo, idxs=None):\n",
    "        self.demo = demo\n",
    "\n",
    "        # get states and actions\n",
    "        states = []\n",
    "        actions = []\n",
    "        for state, action in self.demo:\n",
    "            states.append(state)\n",
    "            actions.append(action.value)\n",
    "\n",
    "        idxs = [i for i in range(len(self.demo))] if idxs is None else idxs\n",
    "        \n",
    "        states = torch.tensor(states)\n",
    "        self.states = states[idxs]\n",
    "        \n",
    "        actions = torch.tensor(actions)\n",
    "        self.actions = actions[idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.demo)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        state = self.states[idx]\n",
    "        action = self.actions[idx]\n",
    "\n",
    "        return state, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load all demonstrations\n",
    "demo_dir = '/Users/emilyjin/Code/behavior/mini_behavior/installing_a_printer/demo_8'\n",
    "demos = load_demos(demo_dir) # list of (state, action) tuples\n",
    "\n",
    "def get_dataloaders(split=None, batch_size=32):\n",
    "    if split:\n",
    "        train_idxs, test_idxs = get_split_idx(len(demos), split)\n",
    "        train_dataset = DemoDataset(demos, train_idxs)\n",
    "        test_dataset = DemoDataset(demos, test_idxs)\n",
    "    else:\n",
    "        train_dataset = DemoDataset(demos)\n",
    "        test_dataset = train_dataset\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset)\n",
    "    \n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_policy(small):\n",
    "    if small:\n",
    "        mlp_policy = nn.Sequential(\n",
    "            nn.Linear(state_space_size, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, action_space_size),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        mlp_policy = nn.Sequential(\n",
    "            nn.Linear(state_space_size, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(256, 100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, action_space_size),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    return mlp_policy\n",
    "\n",
    "def get_criterion():\n",
    "    return nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(train_dataloader, lr, max_epochs, model_size):\n",
    "    losses = []\n",
    "\n",
    "    policy = get_policy(model_size)\n",
    "    criterion = get_criterion()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "            \n",
    "    for epoch in range(max_epoch):\n",
    "        total_loss = 0\n",
    "        for s, a in train_dataloader:\n",
    "            # transfer to device\n",
    "            s, a = s.to(device), a.to(device)\n",
    "            criterion.zero_grad()\n",
    "\n",
    "            # model computations\n",
    "            a_pred = policy(s.type(torch.float))\n",
    "            loss = criterion(a_pred, a)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"[EPOCH]: %i, [CE LOSS]: %.6f\" % (epoch+1, total_loss / len(train_dataloader)))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        losses.append(total_loss / len(train_dataloader))\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            save_model_and_plot(policy, losses, lr, batch_size, epoch, model_dir)\n",
    "            \n",
    "    return losses, policy, criterion\n",
    "    \n",
    "    \n",
    "def test_policy(test_dataloader, policy, criterion):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        correct = 0\n",
    "        total_loss = 0\n",
    "        for s, a in test_dataloader:\n",
    "            s, a = s.to(device), a.to(device)\n",
    "            a_pred = policy(s.type(torch.float))\n",
    "            loss = criterion(a_pred, a)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if a == np.argmax(a_pred):\n",
    "                correct += 1\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    accuracy = correct / len(test_dataloader)\n",
    "    \n",
    "    print(f'TEST [CE LOSS]: {avg_loss}')\n",
    "    print(f'TEST [ACCURACY]: {accuracy}')\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def save_model_and_plot(policy, losses, lr, batch_size, epochs, model_dir):\n",
    "    # save plot\n",
    "    model_filename = f\"lr={lr}_batch={batch_size}_epochs={epochs}\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    torch.save(policy, model_path)\n",
    "\n",
    "#     # save plot\n",
    "#     loss_plots_dir = '/Users/emilyjin/Code/behavior/mini_behavior/mini_behavior/loss_plots/loss_plots_8'\n",
    "#     loss_plot_path = os.path.join(loss_plots_dir, f'{model_filename}.png')\n",
    "\n",
    "#     plt.plot(losses, label='train loss')\n",
    "#     plt.xlabel(\"num epochs\")\n",
    "#     plt.ylabel(\"ce loss\")\n",
    "#     plt.show()\n",
    "#     plt.savefig(loss_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_epoch \u001b[38;5;129;01min\u001b[39;00m max_epochs:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs:\n\u001b[0;32m---> 17\u001b[0m         losses, policy, criterion \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m         avg_loss, accuracy \u001b[38;5;241m=\u001b[39m test_policy(test_dataloader, policy, criterion)\n\u001b[1;32m     20\u001b[0m         model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/emilyjin/Code/behavior/mini_behavior/installing_a_printer/models_8/small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(train_dataloader, lr, max_epochs, model_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, a \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# transfer to device\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     s, a \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mto(device), a\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# model computations\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     a_pred \u001b[38;5;241m=\u001b[39m policy(s\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat))\n",
      "File \u001b[0;32m~/Code/behavior/behavior_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1892\u001b[0m, in \u001b[0;36mModule.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzero_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, set_to_none: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1885\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets gradients of all model parameters to zero. See similar function\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;124;03m    under :class:`torch.optim.Optimizer` for more context.\u001b[39;00m\n\u001b[1;32m   1887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;124;03m            See :meth:`torch.optim.Optimizer.zero_grad` for details.\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_is_replica\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1893\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling .zero_grad() from a module created with nn.DataParallel() has no effect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1895\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameters are copied (in a differentiable manner) from the original module. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1896\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means they are not leaf nodes in autograd and so don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt accumulate gradients. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you need gradients in your forward method, consider using autograd.grad instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/Code/behavior/behavior_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1195\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m:\n\u001b[1;32m   1196\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _parameters:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split = None\n",
    "test_losses = {}\n",
    "test_accuracies = {}\n",
    "\n",
    "\n",
    "# hyperparam tuning\n",
    "max_epochs = [100, 150, 200]\n",
    "lrs = [5e-4, 2.5e-4, 1e-4]\n",
    "batch_sizes = [64, 128]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # get dataloaders\n",
    "    train_dataloader, test_dataloader = get_dataloaders(split, batch_size)\n",
    "    \n",
    "    for max_epoch in max_epochs:\n",
    "        for lr in lrs:\n",
    "            losses, policy, criterion = train_epochs(train_dataloader, lr, max_epoch, True)\n",
    "            avg_loss, accuracy = test_policy(test_dataloader, policy, criterion)\n",
    "            \n",
    "            model_dir = \"/Users/emilyjin/Code/behavior/mini_behavior/installing_a_printer/models_8/small\"\n",
    "            save_model_and_plot(policy, losses, lr, batch_size, max_epoch, model_dir)\n",
    "            \n",
    "            params = f'lr={lr}_batch={batch_size}_epochs={max_epoch}'\n",
    "            test_losses[params] = avg_loss\n",
    "            test_accuracies[params] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_loss\n",
      "model: lr=0.00025_batch=64_epochs=200\n",
      "loss: 0.6779619894792943\n",
      "best_accuracy\n",
      "model: lr=0.0001_batch=64_epochs=100\n",
      "loss: 0.6927822047195643\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e100\n",
    "best_loss_params = None\n",
    "best_accuracy = -1\n",
    "best_accuracy_params = None\n",
    "\n",
    "for params in test_losses.keys():\n",
    "    if test_losses[params] < best_loss:\n",
    "        best_loss = test_losses[params]\n",
    "        best_loss_params = params\n",
    "    if test_accuracies[params] > best_accuracy:\n",
    "        best_accuracy = test_accuracies[params]\n",
    "        best_accuracy_params = params\n",
    "\n",
    "print(f'best_loss')\n",
    "print(f'model: {best_loss_params}')\n",
    "print(f'loss: {best_loss}')\n",
    "      \n",
    "print(f'best_accuracy')\n",
    "print(f'model: {best_accuracy_params}')\n",
    "print(f'loss: {best_accuracy}')   \n",
    "      \n",
    "# loss_plots_dir = '/Users/emilyjin/Code/behavior/mini_behavior/mini_behavior/loss_plots'\n",
    "# loss_plot_path = os.path.join(loss_plots_dir, f'{model_filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 9, [CE LOSS]: 1.453768\n"
     ]
    }
   ],
   "source": [
    "# large model\n",
    "split = None\n",
    "large_test_losses = {}\n",
    "large_test_accuracies = {}\n",
    "\n",
    "\n",
    "# hyperparam tuning\n",
    "max_epochs = [200]\n",
    "lrs = [5e-4, 2.5e-4, 1e-4, 5e-5, 1e-5, 1e-6]\n",
    "batch_sizes = [128]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # get dataloaders\n",
    "    train_dataloader, test_dataloader = get_dataloaders(split, batch_size)\n",
    "    \n",
    "    for max_epoch in max_epochs:\n",
    "        for lr in lrs:\n",
    "            losses, policy, criterion = train_epochs(train_dataloader, lr, max_epoch, False)\n",
    "            avg_loss, accuracy = test_policy(test_dataloader, policy, criterion)\n",
    "            \n",
    "            model_dir = \"/Users/emilyjin/Code/behavior/mini_behavior/installing_a_printer/models_8/large\"\n",
    "            save_model_and_plot(policy, losses, lr, batch_size, max_epoch, model_dir)\n",
    "            \n",
    "            params = f'lr={lr}_batch={batch_size}_epochs={max_epoch}'\n",
    "            large_test_losses[params] = avg_loss\n",
    "            large_test_accuracies[params] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large model\n",
    "best_loss = 1e100\n",
    "best_loss_params = None\n",
    "best_accuracy = -1\n",
    "best_accuracy_params = None\n",
    "\n",
    "for params in large_test_losses.keys():\n",
    "    if large_test_losses[params] < best_loss:\n",
    "        best_loss = large_test_losses[params]\n",
    "        best_loss_params = params\n",
    "    if large_test_accuracies[params] > best_accuracy:\n",
    "        best_accuracy = large_test_accuracies[params]\n",
    "        best_accuracy_params = params\n",
    "\n",
    "print(f'best_loss')\n",
    "print(f'model: {best_loss_params}')\n",
    "print(f'loss: {best_loss}')\n",
    "      \n",
    "print(f'best_accuracy')\n",
    "print(f'model: {best_accuracy_params}')\n",
    "print(f'loss: {best_accuracy}')   \n",
    "      \n",
    "# loss_plots_dir = '/Users/emilyjin/Code/behavior/mini_behavior/mini_behavior/loss_plots'\n",
    "# loss_plot_path = os.path.join(loss_plots_dir, f'{model_filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
